{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBQtKjZAiVEi",
        "outputId": "d106b4e4-ba4a-4481-f777-8eea6b23c5e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /Users/anokhimehta/.cache/kagglehub/datasets/tboyle10/medicaltranscriptions/versions/1\n"
          ]
        }
      ],
      "source": [
        "# Ensure kagglehub is available and give a clear message if not\n",
        "try:\n",
        "    import kagglehub\n",
        "except ModuleNotFoundError:\n",
        "    raise ModuleNotFoundError(\"kagglehub is not installed. Install with `pip install kagglehub` or use the Kaggle API instead.\")\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"tboyle10/medicaltranscriptions\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8yC2nddihzd",
        "outputId": "f3342dec-7b95-4133-e061-d3290c578f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in dataset: 4999\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(4999, 6)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#preview dataset\n",
        "import pandas as pd\n",
        "orig_df = pd.read_csv(path + \"/mtsamples.csv\")\n",
        "orig_df.head()\n",
        "print(\"Number of rows in dataset:\", len(orig_df))\n",
        "orig_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFrMxDJgl18c",
        "outputId": "564525a9-02aa-45a6-e448-6b21a7a07eb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "medical_specialty\n",
            "Surgery                          1103\n",
            "Consult - History and Phy.        516\n",
            "Cardiovascular / Pulmonary        372\n",
            "Orthopedic                        355\n",
            "Radiology                         273\n",
            "General Medicine                  259\n",
            "Gastroenterology                  230\n",
            "Neurology                         223\n",
            "SOAP / Chart / Progress Notes     166\n",
            "Obstetrics / Gynecology           160\n",
            "Urology                           158\n",
            "Discharge Summary                 108\n",
            "ENT - Otolaryngology               98\n",
            "Neurosurgery                       94\n",
            "Hematology - Oncology              90\n",
            "Ophthalmology                      83\n",
            "Nephrology                         81\n",
            "Emergency Room Reports             75\n",
            "Pediatrics - Neonatal              70\n",
            "Pain Management                    62\n",
            "Psychiatry / Psychology            53\n",
            "Office Notes                       51\n",
            "Podiatry                           47\n",
            "Dermatology                        29\n",
            "Cosmetic / Plastic Surgery         27\n",
            "Dentistry                          27\n",
            "Letters                            23\n",
            "Physical Medicine - Rehab          21\n",
            "Sleep Medicine                     20\n",
            "Endocrinology                      19\n",
            "Bariatrics                         18\n",
            "IME-QME-Work Comp etc.             16\n",
            "Chiropractic                       14\n",
            "Rheumatology                       10\n",
            "Diets and Nutritions               10\n",
            "Speech - Language                   9\n",
            "Autopsy                             8\n",
            "Lab Medicine - Pathology            8\n",
            "Allergy / Immunology                7\n",
            "Hospice - Palliative Care           6\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 1. Check class distribution after cleaning\n",
        "print(orig_df['medical_specialty'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm0eKjhyinR7",
        "outputId": "d73c4143-ba19-47b8-c629-efb43716befc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "medical_specialty\n",
            "Surgery                          1021\n",
            "Orthopedic                        303\n",
            "Cardiovascular / Pulmonary        280\n",
            "Radiology                         251\n",
            "Consult - History and Phy.        234\n",
            "Gastroenterology                  195\n",
            "Neurology                         168\n",
            "General Medicine                  146\n",
            "SOAP / Chart / Progress Notes     142\n",
            "Urology                           140\n",
            "Obstetrics / Gynecology           130\n",
            "ENT - Otolaryngology               84\n",
            "Neurosurgery                       81\n",
            "Ophthalmology                      79\n",
            "Discharge Summary                  77\n",
            "Nephrology                         63\n",
            "Hematology - Oncology              62\n",
            "Pain Management                    58\n",
            "Office Notes                       44\n",
            "Pediatrics - Neonatal              42\n",
            "Podiatry                           42\n",
            "Emergency Room Reports             31\n",
            "Dermatology                        25\n",
            "Dentistry                          25\n",
            "Cosmetic / Plastic Surgery         25\n",
            "Letters                            20\n",
            "Psychiatry / Psychology            19\n",
            "Sleep Medicine                     18\n",
            "Bariatrics                         18\n",
            "Endocrinology                      15\n",
            "Physical Medicine - Rehab          11\n",
            "Diets and Nutritions               10\n",
            "Speech - Language                   8\n",
            "Lab Medicine - Pathology            8\n",
            "Rheumatology                        7\n",
            "Hospice - Palliative Care           5\n",
            "Chiropractic                        4\n",
            "IME-QME-Work Comp etc.              4\n",
            "Allergy / Immunology                3\n",
            "Name: count, dtype: int64\n",
            "Number of rows in dataset: 3898\n"
          ]
        }
      ],
      "source": [
        "#clean dataset first\n",
        "#create new df (df) that is subset of orig_df\n",
        "#drop any empty rows\n",
        "#drop Unnamed:0 (index col), sample_name?,\n",
        "#description seems not too informative, so maybe we can drop that as well?\n",
        "df = orig_df.drop(['Unnamed: 0', 'sample_name', 'description'], axis=1)\n",
        "df = df[df['transcription'].notna() & df['keywords'].notna()]\n",
        "df.shape\n",
        "\n",
        "#reorder to move medical_specialty col to the right\n",
        "df = df[['transcription', 'keywords', 'medical_specialty']]\n",
        "df.head()\n",
        "\n",
        "# 1. Check class distribution after cleaning\n",
        "print(df['medical_specialty'].value_counts())\n",
        "\n",
        "#print num rows\n",
        "print(\"Number of rows in dataset:\", len(df))\n",
        "\n",
        "#cleaning seems to drop about 1000 rows of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pPsNZ-kcsQHc"
      },
      "outputs": [],
      "source": [
        "#combine some categories\n",
        "\n",
        "mapping = {\n",
        "    'Cosmetic / Plastic Surgery': 'Surgery',\n",
        "    'Neurosurgery': 'Surgery',\n",
        "    'Surgery': 'Surgery',\n",
        "    'ENT - Otolaryngology': 'Surgery',\n",
        "\n",
        "    'Orthopedic': 'Orthopedics',\n",
        "    'Podiatry': 'Orthopedics',\n",
        "    'Physical Medicine - Rehab': 'Orthopedics',\n",
        "    'Chiropractic': 'Orthopedics',\n",
        "    'Rheumatology': 'Orthopedics',\n",
        "\n",
        "    'Cardiovascular / Pulmonary': 'Cardiovascular/Pulmonary',\n",
        "\n",
        "    'Gastroenterology': 'Gastroenterology',\n",
        "    'Bariatrics': 'Gastroenterology',\n",
        "\n",
        "    'Neurology': 'Neurology',\n",
        "    'Psychiatry / Psychology': 'Neurology',\n",
        "    'Pain Management': 'Neurology',\n",
        "    'Sleep Medicine': 'Neurology',\n",
        "\n",
        "    'Obstetrics / Gynecology': 'Women/Men\\'s Reproductive Health',\n",
        "    'Urology': 'Women/Men\\'s Reproductive Health',\n",
        "\n",
        "    'Hematology - Oncology': 'Kidney & Blood/Oncology',\n",
        "    'Nephrology': 'Kidney & Blood/Oncology',\n",
        "\n",
        "    'Radiology': 'Radiology & Diagnostics',\n",
        "    'Lab Medicine - Pathology': 'Radiology & Diagnostics',\n",
        "\n",
        "    'General Medicine': 'General Medicine',\n",
        "    'Consult - History and Phy.': 'General Medicine',\n",
        "    'SOAP / Chart / Progress Notes': 'General Medicine',\n",
        "    'Discharge Summary': 'General Medicine',\n",
        "    'Office Notes': 'General Medicine',\n",
        "    'Letters': 'General Medicine',\n",
        "    'Hospice - Palliative Care': 'General Medicine',\n",
        "    'IME-QME-Work Comp etc.': 'General Medicine',\n",
        "    'Emergency Room Reports': 'General Medicine',\n",
        "\n",
        "    'Ophthalmology': 'Other Specialties',\n",
        "    'Dermatology': 'Other Specialties',\n",
        "    'Pediatrics - Neonatal': 'Other Specialties',\n",
        "    'Dentistry': 'Other Specialties',\n",
        "    'Speech - Language': 'Other Specialties',\n",
        "    'Endocrinology': 'Other Specialties',\n",
        "    'Diets and Nutritions': 'Other Specialties',\n",
        "    'Allergy / Immunology': 'Other Specialties',\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C87KVOW1oLC",
        "outputId": "aed5d68f-49e5-493a-fd90-1d8b44552c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "specialty_grouped\n",
            "Surgery                            1211\n",
            "General Medicine                    703\n",
            "Orthopedics                         367\n",
            "Cardiovascular/Pulmonary            280\n",
            "Women/Men's Reproductive Health     270\n",
            "Neurology                           263\n",
            "Radiology & Diagnostics             259\n",
            "Gastroenterology                    213\n",
            "Other Specialties                   207\n",
            "Kidney & Blood/Oncology             125\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df['medical_specialty'] = df['medical_specialty'].str.strip()\n",
        "df['specialty_grouped'] = df['medical_specialty'].map(mapping)\n",
        "\n",
        "# Check results\n",
        "print(df['specialty_grouped'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine multiple text fields\n",
        "df['combined_text'] = df['transcription'].fillna('') + ' ' + df['keywords'].fillna('')\n",
        "X = df['combined_text']\n",
        "y = df['specialty_grouped']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes -> (3118,) (780,) (3118,) (780,)\n"
          ]
        }
      ],
      "source": [
        "#split into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['combined_text']\n",
        "y = df['specialty_grouped']\n",
        "\n",
        "# Correct assignment order: X_train, X_test, y_train, y_test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# quick sanity-check shapes\n",
        "print('Shapes ->', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TF-IDF Vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=10000,\n",
        "    ngram_range=(1,3),\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.3.5 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
            "    handle._run()\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
            "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
            "    await result\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3123, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3178, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3641, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/v5/_qckl3n97ysg0xys6vpbj69h0000gn/T/ipykernel_69719/3678181171.py\", line 2, in <module>\n",
            "    import torch\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/Users/anokhimehta/miniconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 ['Cardiovascular/Pulmonary' 'Gastroenterology' 'General Medicine'\n",
            " 'Kidney & Blood/Oncology' 'Neurology' 'Orthopedics' 'Other Specialties'\n",
            " 'Radiology & Diagnostics' 'Surgery' \"Women/Men's Reproductive Health\"]\n"
          ]
        }
      ],
      "source": [
        "#BERT model training\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# Ecode labels because BERT cannot handle string labels \n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['specialty_grouped'])\n",
        "\n",
        "num_labels = len(label_encoder.classes_)\n",
        "print(num_labels, label_encoder.classes_)\n",
        "\n",
        "#tokenize\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=512)\n",
        "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=512)\n",
        "\n",
        "#map labels to encoded labels\n",
        "y_train_encoded = label_encoder.transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#create pytorch dataset\n",
        "class MedicalDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(int(self.labels[idx]))\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "\n",
        "train_dataset = MedicalDataset(train_encodings, y_train_encoded)\n",
        "test_dataset = MedicalDataset(test_encodings, y_test_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#load BERT model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "#define metrics\n",
        "def compute_metrics(pred):\n",
        "    logits, labels = pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {'accuracy': acc}\n",
        "\n",
        "    # labels = pred.label_ids\n",
        "    # preds = pred.predictions.argmax(-1)\n",
        "    # precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    # acc = accuracy_score(labels, preds)\n",
        "    # return {\n",
        "    #     'accuracy': acc,\n",
        "    #     'f1': f1,\n",
        "    #     'precision': precision,\n",
        "    #     'recall': recall\n",
        "    # }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,   # Reduce if out of memory\n",
        "    per_device_eval_batch_size=8,\n",
        "    # warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='macro_f1',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "#trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Could not infer dtype of numpy.int64",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#train BERT model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#evaluate\u001b[39;00m\n\u001b[32m      5\u001b[39m trainer.evaluate()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/transformers/trainer.py:2618\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2616\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2617\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2618\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2619\u001b[39m \u001b[38;5;66;03m# Store the number of batches for current gradient accumulation\u001b[39;00m\n\u001b[32m   2620\u001b[39m \u001b[38;5;66;03m# This is used to correctly scale the loss when the last accumulation step has fewer batches\u001b[39;00m\n\u001b[32m   2621\u001b[39m \u001b[38;5;28mself\u001b[39m.current_gradient_accumulation_steps = \u001b[38;5;28mlen\u001b[39m(batch_samples)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/transformers/trainer.py:5654\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches, device)\u001b[39m\n\u001b[32m   5652\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5653\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5654\u001b[39m         batch_samples.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   5655\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5656\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/accelerate/data_loader.py:567\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    565\u001b[39m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m     current_batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    569\u001b[39m     \u001b[38;5;28mself\u001b[39m.end()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    634\u001b[39m         \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    635\u001b[39m         \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    674\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    677\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     49\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     49\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mMedicalDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m      8\u001b[39m     item = {key: torch.tensor(val[idx]) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encodings.items()}\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     item[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m item\n",
            "\u001b[31mRuntimeError\u001b[39m: Could not infer dtype of numpy.int64"
          ]
        }
      ],
      "source": [
        "#train BERT model\n",
        "trainer.train()\n",
        "\n",
        "#evaluate\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model training complete.\n"
          ]
        }
      ],
      "source": [
        "#Logistic Regression Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "print(\"Model training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                 precision    recall  f1-score   support\n",
            "\n",
            "       Cardiovascular/Pulmonary       0.49      0.70      0.58        56\n",
            "               Gastroenterology       0.40      0.72      0.52        43\n",
            "               General Medicine       0.71      0.55      0.62       141\n",
            "        Kidney & Blood/Oncology       0.25      0.44      0.32        25\n",
            "                      Neurology       0.49      0.64      0.55        53\n",
            "                    Orthopedics       0.45      0.64      0.53        73\n",
            "              Other Specialties       0.40      0.61      0.48        41\n",
            "        Radiology & Diagnostics       0.37      0.40      0.39        52\n",
            "                        Surgery       0.72      0.26      0.38       242\n",
            "Women/Men's Reproductive Health       0.46      0.78      0.58        54\n",
            "\n",
            "                       accuracy                           0.50       780\n",
            "                      macro avg       0.47      0.57      0.49       780\n",
            "                   weighted avg       0.57      0.50      0.49       780\n",
            "\n",
            "Accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "#evaluate model\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "#accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
